{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "# %matplotlib inline\n",
    "\n",
    "# from fastai.vision import *\n",
    "# from fastai.tabular import *\n",
    "# from image_tabular.core import *\n",
    "# from image_tabular.dataset import *\n",
    "# from image_tabular.model import *\n",
    "# from image_tabular.metric import *\n",
    "# import torch\n",
    "\n",
    "\n",
    "# use gpu by default if available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# growth_rate=32 \n",
    "# block_config=(2, 2, 2, 2)\n",
    "# num_init_features=64\n",
    "# bn_size=4\n",
    "# drop_rate=0.5\n",
    "# batch_size=128\n",
    "# patch_size=256\n",
    "# gpuid = 0\n",
    "# num_classes = 4\n",
    "# random.seed(7654788126099255772) \n",
    "# print(torch.cuda.get_device_properties(gpuid))\n",
    "# torch.cuda.set_device(gpuid)\n",
    "# device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')\n",
    "# mdl = DenseNet(growth_rate=growth_rate, block_config=block_config,\n",
    "#                  num_init_features=num_init_features, \n",
    "#                  bn_size=bn_size, \n",
    "#                  drop_rate=drop_rate, \n",
    "#                  num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataname=\"CUP010722\"\n",
    "# checkpoint = torch.load(f\"{dataname}_densenet_best_model.pth\")\n",
    "# mdl.load_state_dict(checkpoint[\"model_dict\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(mdl.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdl.classifier = torch.nn.Sequential(*list(mdl.classifier.children())[:-1])\n",
    "# mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# # increasing few layers in our model\n",
    "# class DenseNetFusion(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(DenseNetFusion, self).__init__()\n",
    "#         self.model = mdl \n",
    "#         self.image_dense_layer_1 = nn.Linear(128 , 64)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.batchnorm = nn.BatchNorm1d(64)\n",
    "#         self.dropout = nn.Dropout2d(0.5)\n",
    "#         self.image_dense_layer_2 = nn.Linear(64, 10)\n",
    "#         self.BilinearPool = nn.Bilinear(10, 10, 10)\n",
    "#         self.final = nn.Linear(10 , 4)\n",
    "# #         self.tabular_dense_layer_1 = nn.Linear(10, 8)\n",
    "# #         self.tabular_dense_layer_2 = nn.Linear(8, 5)        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "#     def forward(self, image_inputs , tabular_data_inputs):\n",
    "#         x_img = self.model.eval(image_inputs)\n",
    "#         # Pooling and final linear layer\n",
    "#         x_img = x_img.flatten(start_dim=1)\n",
    "#         x_img = self.image_dense_layer_1(x_img)\n",
    "#         x_img = self.relu(x_img)\n",
    "#         x_img = self.batchnorm(x_img)\n",
    "#         x_img = self.dropout(x_img)\n",
    "#         x_img = self.image_dense_layer_2(x_img)\n",
    "#         x_img = self.relu(x_img)\n",
    "        \n",
    "        \n",
    "#         tab = self.tabular_dense_layer_1(tabular_data_inputs)\n",
    "#         tab = self.relu(tab)\n",
    "#         tab = self.tabular_dense_layer_2(tab)\n",
    "#         tab = self.relu(tab)\n",
    "#         x = self.BilinearPool(x_img,tab)\n",
    "# #         x = torch.cat((x, tab), dim=1)\n",
    "\n",
    "#         return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # m = nn.ReLU()\n",
    "# model = DenseNetFusion()\n",
    "# model = model.to(device)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = nn.Bilinear(5, 5, 5)\n",
    "# input1 = torch.randn(1, 5)\n",
    "# input2 = torch.randn(1, 5)\n",
    "# output = m(input1, input2)\n",
    "# print(output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#v3.classification\n",
    "#28/11/2018\n",
    "\n",
    "dataname=\"CUPBinlinFusion\"\n",
    "gpuid=0\n",
    "\n",
    "# --- densenet params\n",
    "#these parameters get fed directly into the densenet class, and more description of them can be discovered there\n",
    "num_classes=4    #number of classes in the data mask that we'll aim to predict\n",
    "in_channels= 3  #input channel of the data, RGB = 3\n",
    "\n",
    "\n",
    "growth_rate=32 #down from 32 \n",
    "block_config=(2, 2, 2, 2)\n",
    "num_init_features=64\n",
    "bn_size=4\n",
    "drop_rate=0.5\n",
    "\n",
    "\n",
    "\n",
    "# --- training params\n",
    "batch_size=128\n",
    "patch_size=256 #currently, this needs to be 224 due to densenet architecture\n",
    "num_epochs = 100\n",
    "phases = [\"train\",\"val\"] #how many phases did we create databases for?\n",
    "validation_phases= [\"val\"] #when should we do valiation? note that validation is *very* time consuming, so as opposed to doing for both training and validation, we do it only for vlaidation at the end of the epoch\n",
    "                           #additionally, using simply [], will skip validation entirely, drastically speeding things up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import DenseNet\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import sys, glob\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import time\n",
    "import math\n",
    "import tables\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for pretty printing of current time and remaining time\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent+.00001)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2080 Ti', major=7, minor=5, total_memory=11263MB, multi_processor_count=68)\n"
     ]
    }
   ],
   "source": [
    "#specify if we should use a GPU (cuda) or only the CPU\n",
    "print(torch.cuda.get_device_properties(gpuid))\n",
    "torch.cuda.set_device(gpuid)\n",
    "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model according to the paramters specified above and copy it to the GPU. finally print out the number of trainable parameters\n",
    " \n",
    "# model = DenseNet(growth_rate=growth_rate, block_config=block_config,\n",
    "#                  num_init_features=num_init_features, \n",
    "#                  bn_size=bn_size, \n",
    "#                  drop_rate=drop_rate, \n",
    "#                  num_classes=num_classes).to(device)\n",
    "# #model = DenseNet(growth_rate=32, block_config=(6, 12, 24, 16), #these represent the default parameters\n",
    "# #                 num_init_features=64, bn_size=4, drop_rate=0, num_classes=3)\n",
    "\n",
    "# print(f\"total params: \\t{sum([np.prod(p.size()) for p in model.parameters()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='NVIDIA GeForce RTX 2080 Ti', major=7, minor=5, total_memory=11263MB, multi_processor_count=68)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import DenseNet\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import tables\n",
    "import random\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "growth_rate=32 \n",
    "block_config=(2, 2, 2, 2)\n",
    "num_init_features=64\n",
    "bn_size=4\n",
    "drop_rate=0.5\n",
    "batch_size=128\n",
    "patch_size=256\n",
    "gpuid = 0\n",
    "num_classes = 4\n",
    "random.seed(7654788126099255772) \n",
    "print(torch.cuda.get_device_properties(gpuid))\n",
    "torch.cuda.set_device(gpuid)\n",
    "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')\n",
    "# mdl = DenseNet(growth_rate=growth_rate, block_config=block_config,\n",
    "#                  num_init_features=num_init_features, \n",
    "#                  bn_size=bn_size, \n",
    "#                  drop_rate=drop_rate, \n",
    "#                  num_classes=num_classes).to(device)\n",
    "# pretrained_dataname=\"CUP010722\"\n",
    "# checkpoint = torch.load(f\"{pretrained_dataname}_densenet_best_model.pth\")\n",
    "# mdl.load_state_dict(checkpoint[\"model_dict\"])\n",
    "# mdl.classifier = torch.nn.Sequential(*list(mdl.classifier.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# increasing few layers in our model\n",
    "class DenseNetFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNetFusion, self).__init__()\n",
    "        self.image_dense_layer_1 = nn.Linear(300 , 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.image_dense_layer_2 = nn.Linear(100, 10)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.BilinearPool = nn.Bilinear(10, 10, 10)\n",
    "        self.final = nn.Linear(10 , 4)\n",
    "        self.tabular_dense_layer_1 = nn.Linear(10, 10)\n",
    "#         self.tabular_dense_layer_2 = nn.Linear(8, 5)        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def forward(self, image_inputs , tabular_data_inputs):\n",
    "#       DL data\n",
    "        x_img = image_inputs\n",
    "        x_img = self.image_dense_layer_1(x_img)\n",
    "        x_img = self.relu(x_img)\n",
    "        x_img = self.batchnorm1(x_img)\n",
    "        x_img = self.dropout(x_img)\n",
    "        x_img = self.image_dense_layer_2(x_img)\n",
    "        x_img = self.relu(x_img)\n",
    "\n",
    "        \n",
    "#       Tabular data\n",
    "        tab = self.tabular_dense_layer_1(torch.tensor(tabular_data_inputs, device=device).float())\n",
    "        tab = self.relu(tab)\n",
    "        x = self.BilinearPool(x_img,tab)\n",
    "#         x = torch.cat((x, tab), dim=1)\n",
    "\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# increasing few layers in our model\n",
    "class DenseNetFusion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenseNetFusion, self).__init__()\n",
    "        self.image_dense_layer_1 = nn.Linear(300 , 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.batchnorm1 = nn.BatchNorm1d(100)\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.image_dense_layer_2 = nn.Linear(100, 10)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.BilinearPool = nn.Bilinear(10, 10, 10)\n",
    "        self.final = nn.Linear(20 , 4)\n",
    "        self.tabular_dense_layer_1 = nn.Linear(10, 10)\n",
    "#         self.tabular_dense_layer_2 = nn.Linear(8, 5)        \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "    def forward(self, image_inputs , tabular_data_inputs):\n",
    "#       DL data\n",
    "        x_img = image_inputs\n",
    "        x_img = self.image_dense_layer_1(x_img)\n",
    "        x_img = self.relu(x_img)\n",
    "        x_img = self.batchnorm1(x_img)\n",
    "        x_img = self.dropout(x_img)\n",
    "        x_img = self.image_dense_layer_2(x_img)\n",
    "        x_img = self.relu(x_img)\n",
    "\n",
    "        \n",
    "#       Tabular data\n",
    "        tab = self.tabular_dense_layer_1(torch.tensor(tabular_data_inputs, device=device).float())\n",
    "        tab = self.relu(tab)\n",
    "        x = torch.cat((x_img,tab), dim=1)\n",
    "#         x = torch.cat((x, tab), dim=1)\n",
    "\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNetFusion(\n",
       "  (image_dense_layer_1): Linear(in_features=300, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (batchnorm1): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (dropout): Dropout2d(p=0.5, inplace=False)\n",
       "  (image_dense_layer_2): Linear(in_features=100, out_features=10, bias=True)\n",
       "  (BilinearPool): Bilinear(in1_features=10, in2_features=10, out_features=10, bias=True)\n",
       "  (final): Linear(in_features=20, out_features=4, bias=True)\n",
       "  (tabular_dense_layer_1): Linear(in_features=10, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DenseNetFusion()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(model.image_dense_layer_1.parameters()) + \\\n",
    "         list(model.image_dense_layer_2.parameters()) + \\\n",
    "         list(model.tabular_dense_layer_1.parameters()) + \\\n",
    "         list(model.final.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total params: \t31304\n"
     ]
    }
   ],
   "source": [
    "print(f\"total params: \\t{sum([np.prod(p.size()) for p in params])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this defines our dataset class which will be used by the dataloader\n",
    "class Dataset(object):\n",
    "    def __init__(self, fname ,img_transform=None):\n",
    "        #nothing special here, just internalizing the constructor parameters\n",
    "        self.fname=fname\n",
    "\n",
    "        self.img_transform=img_transform\n",
    "        \n",
    "        with tables.open_file(self.fname,'r') as db:\n",
    "            self.classsizes=db.root.classsizes[:]\n",
    "            self.nitems=db.root.imgs.shape[0]\n",
    "        \n",
    "        self.imgs = None\n",
    "        self.labels = None\n",
    "        self.hc = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        #opening should be done in __init__ but seems to be\n",
    "        #an issue with multithreading so doing here. need to do it everytime, otherwise hdf5 crashes\n",
    "\n",
    "        with tables.open_file(self.fname,'r') as db:\n",
    "            self.imgs=db.root.DLfeats\n",
    "            self.labels=db.root.labels\n",
    "            self.hc = db.root.HCFeats\n",
    "\n",
    "            #get the requested image and mask from the pytable\n",
    "            img = self.imgs[index,:]\n",
    "            label = self.labels[index]\n",
    "            handFeats = self.hc[index,:]\n",
    "        \n",
    "        \n",
    "        img_new = img\n",
    "        \n",
    "        if self.img_transform is not None:\n",
    "            img_new = self.img_transform(img)\n",
    "\n",
    "\n",
    "        return img_new, label, img, handFeats\n",
    "    def __len__(self):\n",
    "        return self.nitems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size:\t15870\n",
      "val dataset size:\t6802\n"
     ]
    }
   ],
   "source": [
    "img_transform = transforms.Compose([\n",
    "     transforms.ToPILImage(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(size=(patch_size,patch_size),pad_if_needed=True), \n",
    "    transforms.RandomResizedCrop(size=patch_size),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=.5),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset={}\n",
    "dataLoader={}\n",
    "for phase in phases: #now for each of the phases, we're creating the dataloader\n",
    "                     #interestingly, given the batch size, i've not seen any improvements from using a num_workers>0\n",
    "    \n",
    "    dataset[phase]=Dataset(f\"./{dataname}_{phase}.pytable\", img_transform=None)\n",
    "    dataLoader[phase]=DataLoader(dataset[phase], batch_size=batch_size, \n",
    "                                shuffle=True, num_workers=0,pin_memory=True) #previously num_workers=8\n",
    "    print(f\"{phase} dataset size:\\t{len(dataset[phase])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x14e352fd888>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize a single example to verify that it is correct\n",
    "(img, label, img_old, handFeats)=dataset[\"train\"][27]\n",
    "# fig, ax = plt.subplots(1,2, figsize=(10,4))  # 1 row, 2 columns\n",
    "handFeats\n",
    "#build output showing patch after augmentation and original patch\n",
    "# ax[0].imshow(np.moveaxis(img,0,-1))\n",
    "# ax[1].imshow(img_old)\n",
    "\n",
    "print(label)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(params,lr=1e-5) #adam is going to be the most robust, though perhaps not the best performing, typically a good place to start\n",
    "# optim = torch.optim.SGD(model.parameters(),\n",
    "#                           lr=.1,\n",
    "#                           momentum=0.9,\n",
    "#                           weight_decay=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 1e-05\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6786, 0.7062, 0.7739, 0.8413], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#we have the ability to weight individual classes, in this case we'll do so based on their presense in the trainingset\n",
    "#to avoid biasing any particular class\n",
    "nclasses = dataset[\"train\"].classsizes.shape[0]\n",
    "class_weight=dataset[\"train\"].classsizes\n",
    "class_weight = torch.from_numpy(1-class_weight/class_weight.sum()).type('torch.FloatTensor').to(device)\n",
    "\n",
    "print(class_weight) #show final used weights, make sure that they're reasonable before continouing\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\mvp\\venv\\lib\\site-packages\\ipykernel_launcher.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "e:\\mvp\\venv\\lib\\site-packages\\ipykernel_launcher.py:49: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 29s (- 72m 56s) ([1/150] 0%), train loss: 2.3630 test loss: 7.9739  **\n",
      "0m 58s (- 71m 46s) ([2/150] 1%), train loss: 2.3219 test loss: 7.8271  **\n",
      "1m 27s (- 71m 1s) ([3/150] 2%), train loss: 2.2932 test loss: 7.8819\n",
      "1m 55s (- 70m 15s) ([4/150] 2%), train loss: 2.2602 test loss: 7.8776\n",
      "2m 23s (- 69m 33s) ([5/150] 3%), train loss: 2.2342 test loss: 7.6950  **\n",
      "2m 52s (- 68m 59s) ([6/150] 4%), train loss: 2.2112 test loss: 7.6345  **\n",
      "3m 20s (- 68m 23s) ([7/150] 4%), train loss: 2.1894 test loss: 7.7193\n",
      "3m 49s (- 67m 56s) ([8/150] 5%), train loss: 2.1736 test loss: 7.5850  **\n",
      "4m 18s (- 67m 28s) ([9/150] 6%), train loss: 2.1566 test loss: 7.5111  **\n",
      "4m 47s (- 66m 58s) ([10/150] 6%), train loss: 2.1449 test loss: 7.4790  **\n",
      "5m 15s (- 66m 31s) ([11/150] 7%), train loss: 2.1313 test loss: 7.5285\n",
      "5m 44s (- 66m 1s) ([12/150] 8%), train loss: 2.1176 test loss: 7.4409  **\n",
      "6m 13s (- 65m 33s) ([13/150] 8%), train loss: 2.1116 test loss: 7.4140  **\n",
      "6m 41s (- 65m 3s) ([14/150] 9%), train loss: 2.0989 test loss: 7.3988  **\n",
      "7m 10s (- 64m 35s) ([15/150] 10%), train loss: 2.0875 test loss: 7.3651  **\n",
      "7m 39s (- 64m 5s) ([16/150] 10%), train loss: 2.0818 test loss: 7.3010  **\n",
      "8m 7s (- 63m 36s) ([17/150] 11%), train loss: 2.0711 test loss: 7.3525\n",
      "8m 36s (- 63m 8s) ([18/150] 12%), train loss: 2.0642 test loss: 7.2455  **\n",
      "9m 5s (- 62m 38s) ([19/150] 12%), train loss: 2.0544 test loss: 38.4428\n",
      "9m 33s (- 62m 9s) ([20/150] 13%), train loss: 2.0470 test loss: 7.1804  **\n",
      "10m 2s (- 61m 40s) ([21/150] 14%), train loss: 2.0397 test loss: 7.1567  **\n",
      "10m 31s (- 61m 11s) ([22/150] 14%), train loss: 2.0291 test loss: 7.1720\n",
      "10m 59s (- 60m 42s) ([23/150] 15%), train loss: 2.0218 test loss: 7.1125  **\n",
      "11m 28s (- 60m 13s) ([24/150] 16%), train loss: 2.0120 test loss: 7.0374  **\n",
      "11m 56s (- 59m 44s) ([25/150] 16%), train loss: 2.0071 test loss: 7.0085  **\n",
      "12m 25s (- 59m 15s) ([26/150] 17%), train loss: 1.9942 test loss: 7.0786\n",
      "12m 54s (- 58m 47s) ([27/150] 18%), train loss: 1.9857 test loss: 7.0064  **\n",
      "13m 23s (- 58m 20s) ([28/150] 18%), train loss: 1.9785 test loss: 7.0433\n",
      "13m 52s (- 57m 51s) ([29/150] 19%), train loss: 1.9719 test loss: 6.9295  **\n",
      "14m 20s (- 57m 22s) ([30/150] 20%), train loss: 1.9615 test loss: 6.9209  **\n",
      "14m 49s (- 56m 53s) ([31/150] 20%), train loss: 1.9541 test loss: 6.8990  **\n",
      "15m 17s (- 56m 24s) ([32/150] 21%), train loss: 1.9472 test loss: 6.8774  **\n",
      "15m 46s (- 55m 55s) ([33/150] 22%), train loss: 1.9386 test loss: 6.8093  **\n",
      "16m 14s (- 55m 25s) ([34/150] 22%), train loss: 1.9313 test loss: 6.8286\n",
      "16m 43s (- 54m 56s) ([35/150] 23%), train loss: 1.9238 test loss: 6.8568\n",
      "17m 11s (- 54m 26s) ([36/150] 24%), train loss: 1.9135 test loss: 6.7479  **\n",
      "17m 40s (- 53m 57s) ([37/150] 24%), train loss: 1.9105 test loss: 6.6790  **\n",
      "18m 8s (- 53m 28s) ([38/150] 25%), train loss: 1.9014 test loss: 6.6908\n",
      "18m 37s (- 53m 0s) ([39/150] 26%), train loss: 1.8931 test loss: 6.6832\n",
      "19m 6s (- 52m 32s) ([40/150] 26%), train loss: 1.8849 test loss: 6.6625  **\n",
      "19m 35s (- 52m 3s) ([41/150] 27%), train loss: 1.8786 test loss: 6.6278  **\n",
      "20m 3s (- 51m 35s) ([42/150] 28%), train loss: 1.8722 test loss: 6.6433\n",
      "20m 32s (- 51m 5s) ([43/150] 28%), train loss: 1.8629 test loss: 6.5710  **\n",
      "21m 0s (- 50m 36s) ([44/150] 29%), train loss: 1.8567 test loss: 6.5853\n",
      "21m 28s (- 50m 7s) ([45/150] 30%), train loss: 1.8519 test loss: 6.7958\n",
      "21m 57s (- 49m 38s) ([46/150] 30%), train loss: 1.8439 test loss: 6.5238  **\n",
      "22m 25s (- 49m 9s) ([47/150] 31%), train loss: 1.8368 test loss: 6.5640\n",
      "22m 54s (- 48m 40s) ([48/150] 32%), train loss: 1.8295 test loss: 6.4108  **\n",
      "23m 23s (- 48m 11s) ([49/150] 32%), train loss: 1.8231 test loss: 6.4100  **\n",
      "23m 51s (- 47m 43s) ([50/150] 33%), train loss: 1.8170 test loss: 6.3443  **\n",
      "24m 20s (- 47m 14s) ([51/150] 34%), train loss: 1.8093 test loss: 6.3672\n",
      "24m 48s (- 46m 45s) ([52/150] 34%), train loss: 1.8038 test loss: 6.3410  **\n",
      "25m 17s (- 46m 17s) ([53/150] 35%), train loss: 1.7972 test loss: 6.3590\n",
      "25m 46s (- 45m 48s) ([54/150] 36%), train loss: 1.7895 test loss: 6.2596  **\n",
      "26m 14s (- 45m 19s) ([55/150] 36%), train loss: 1.7798 test loss: 6.2472  **\n",
      "26m 43s (- 44m 51s) ([56/150] 37%), train loss: 1.7764 test loss: 6.2383  **\n",
      "27m 11s (- 44m 22s) ([57/150] 38%), train loss: 1.7697 test loss: 6.2336  **\n",
      "27m 40s (- 43m 53s) ([58/150] 38%), train loss: 1.7641 test loss: 6.2784\n",
      "28m 8s (- 43m 24s) ([59/150] 39%), train loss: 1.7569 test loss: 6.1317  **\n",
      "28m 37s (- 42m 55s) ([60/150] 40%), train loss: 1.7495 test loss: 6.1644\n",
      "29m 5s (- 42m 27s) ([61/150] 40%), train loss: 1.7439 test loss: 6.1059  **\n",
      "29m 34s (- 41m 58s) ([62/150] 41%), train loss: 1.7361 test loss: 6.1056  **\n",
      "30m 2s (- 41m 29s) ([63/150] 42%), train loss: 1.7282 test loss: 6.0671  **\n",
      "30m 31s (- 41m 0s) ([64/150] 42%), train loss: 1.7222 test loss: 6.0262  **\n",
      "30m 59s (- 40m 31s) ([65/150] 43%), train loss: 1.7164 test loss: 6.0335\n",
      "31m 28s (- 40m 2s) ([66/150] 44%), train loss: 1.7116 test loss: 5.9950  **\n",
      "31m 56s (- 39m 34s) ([67/150] 44%), train loss: 1.7041 test loss: 5.9327  **\n",
      "32m 25s (- 39m 5s) ([68/150] 45%), train loss: 1.6977 test loss: 5.9254  **\n",
      "32m 53s (- 38m 36s) ([69/150] 46%), train loss: 1.6925 test loss: 5.9784\n",
      "33m 22s (- 38m 7s) ([70/150] 46%), train loss: 1.6861 test loss: 5.9340\n",
      "33m 50s (- 37m 39s) ([71/150] 47%), train loss: 1.6801 test loss: 5.8578  **\n",
      "34m 18s (- 37m 10s) ([72/150] 48%), train loss: 1.6748 test loss: 5.8710\n",
      "34m 47s (- 36m 41s) ([73/150] 48%), train loss: 1.6678 test loss: 5.8771\n",
      "35m 15s (- 36m 12s) ([74/150] 49%), train loss: 1.6612 test loss: 5.8128  **\n",
      "35m 44s (- 35m 44s) ([75/150] 50%), train loss: 1.6569 test loss: 5.8053  **\n",
      "36m 12s (- 35m 15s) ([76/150] 50%), train loss: 1.6510 test loss: 5.7800  **\n",
      "36m 41s (- 34m 46s) ([77/150] 51%), train loss: 1.6439 test loss: 5.7529  **\n",
      "37m 9s (- 34m 18s) ([78/150] 52%), train loss: 1.6382 test loss: 5.7548\n",
      "37m 39s (- 33m 50s) ([79/150] 52%), train loss: 1.6330 test loss: 5.6951  **\n",
      "38m 8s (- 33m 22s) ([80/150] 53%), train loss: 1.6270 test loss: 5.6651  **\n",
      "38m 37s (- 32m 53s) ([81/150] 54%), train loss: 1.6211 test loss: 5.6741\n",
      "39m 5s (- 32m 25s) ([82/150] 54%), train loss: 1.6155 test loss: 5.5760  **\n",
      "39m 34s (- 31m 56s) ([83/150] 55%), train loss: 1.6104 test loss: 5.6354\n",
      "40m 2s (- 31m 27s) ([84/150] 56%), train loss: 1.6053 test loss: 5.5747  **\n",
      "40m 31s (- 30m 59s) ([85/150] 56%), train loss: 1.6006 test loss: 5.5690  **\n",
      "40m 59s (- 30m 30s) ([86/150] 57%), train loss: 1.5929 test loss: 5.5171  **\n",
      "41m 28s (- 30m 1s) ([87/150] 57%), train loss: 1.5900 test loss: 5.5483\n",
      "41m 56s (- 29m 33s) ([88/150] 58%), train loss: 1.5830 test loss: 5.5446\n",
      "42m 25s (- 29m 4s) ([89/150] 59%), train loss: 1.5806 test loss: 5.5150  **\n",
      "42m 53s (- 28m 35s) ([90/150] 60%), train loss: 1.5767 test loss: 5.5433\n",
      "43m 22s (- 28m 7s) ([91/150] 60%), train loss: 1.5745 test loss: 5.4351  **\n",
      "43m 50s (- 27m 38s) ([92/150] 61%), train loss: 1.5719 test loss: 5.4276  **\n",
      "44m 19s (- 27m 9s) ([93/150] 62%), train loss: 1.5689 test loss: 5.4590\n",
      "44m 48s (- 26m 41s) ([94/150] 62%), train loss: 1.5649 test loss: 5.4313\n",
      "45m 16s (- 26m 12s) ([95/150] 63%), train loss: 1.5635 test loss: 5.4473\n",
      "45m 44s (- 25m 43s) ([96/150] 64%), train loss: 1.5613 test loss: 5.3637  **\n",
      "46m 13s (- 25m 15s) ([97/150] 64%), train loss: 1.5590 test loss: 5.3373  **\n",
      "46m 42s (- 24m 46s) ([98/150] 65%), train loss: 1.5554 test loss: 5.3294  **\n",
      "47m 10s (- 24m 18s) ([99/150] 66%), train loss: 1.5533 test loss: 5.3463\n",
      "47m 39s (- 23m 49s) ([100/150] 66%), train loss: 1.5495 test loss: 5.2672  **\n",
      "48m 7s (- 23m 20s) ([101/150] 67%), train loss: 1.5475 test loss: 5.2451  **\n",
      "48m 36s (- 22m 52s) ([102/150] 68%), train loss: 1.5459 test loss: 5.2928\n",
      "49m 4s (- 22m 23s) ([103/150] 68%), train loss: 1.5433 test loss: 5.2273  **\n",
      "49m 33s (- 21m 54s) ([104/150] 69%), train loss: 1.5392 test loss: 5.2136  **\n",
      "50m 1s (- 21m 26s) ([105/150] 70%), train loss: 1.5370 test loss: 5.1783  **\n",
      "50m 30s (- 20m 57s) ([106/150] 70%), train loss: 1.5351 test loss: 5.2169\n",
      "50m 58s (- 20m 29s) ([107/150] 71%), train loss: 1.5323 test loss: 5.1896\n",
      "51m 27s (- 20m 0s) ([108/150] 72%), train loss: 1.5294 test loss: 5.1227  **\n",
      "51m 55s (- 19m 31s) ([109/150] 72%), train loss: 1.5275 test loss: 5.1092  **\n",
      "52m 24s (- 19m 3s) ([110/150] 73%), train loss: 1.5249 test loss: 5.1404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52m 52s (- 18m 34s) ([111/150] 74%), train loss: 1.5224 test loss: 5.1048  **\n",
      "53m 21s (- 18m 6s) ([112/150] 74%), train loss: 1.5186 test loss: 5.0710  **\n",
      "53m 49s (- 17m 37s) ([113/150] 75%), train loss: 1.5181 test loss: 5.1119\n",
      "54m 18s (- 17m 8s) ([114/150] 76%), train loss: 1.5144 test loss: 5.0797\n",
      "54m 46s (- 16m 40s) ([115/150] 76%), train loss: 1.5106 test loss: 5.0644  **\n",
      "55m 15s (- 16m 11s) ([116/150] 77%), train loss: 1.5105 test loss: 5.0712\n",
      "55m 43s (- 15m 42s) ([117/150] 78%), train loss: 1.5067 test loss: 5.0530  **\n",
      "56m 12s (- 15m 14s) ([118/150] 78%), train loss: 1.5073 test loss: 5.0604\n",
      "56m 40s (- 14m 45s) ([119/150] 79%), train loss: 1.5026 test loss: 5.0306  **\n",
      "57m 9s (- 14m 17s) ([120/150] 80%), train loss: 1.5032 test loss: 5.0355\n",
      "57m 37s (- 13m 48s) ([121/150] 80%), train loss: 1.5005 test loss: 5.0034  **\n",
      "58m 6s (- 13m 20s) ([122/150] 81%), train loss: 1.4971 test loss: 5.1054\n",
      "58m 34s (- 12m 51s) ([123/150] 82%), train loss: 1.4952 test loss: 4.9914  **\n",
      "59m 3s (- 12m 22s) ([124/150] 82%), train loss: 1.4949 test loss: 4.9938\n",
      "59m 31s (- 11m 54s) ([125/150] 83%), train loss: 1.4930 test loss: 4.9498  **\n",
      "60m 0s (- 11m 25s) ([126/150] 84%), train loss: 1.4903 test loss: 4.9528\n",
      "60m 28s (- 10m 57s) ([127/150] 84%), train loss: 1.4893 test loss: 5.0097\n",
      "60m 57s (- 10m 28s) ([128/150] 85%), train loss: 1.4872 test loss: 4.9290  **\n",
      "61m 25s (- 9m 59s) ([129/150] 86%), train loss: 1.4827 test loss: 4.9805\n",
      "61m 53s (- 9m 31s) ([130/150] 86%), train loss: 1.4829 test loss: 4.9357\n",
      "62m 22s (- 9m 2s) ([131/150] 87%), train loss: 1.4804 test loss: 4.8874  **\n",
      "62m 50s (- 8m 34s) ([132/150] 88%), train loss: 1.4787 test loss: 4.8524  **\n",
      "63m 19s (- 8m 5s) ([133/150] 88%), train loss: 1.4758 test loss: 4.8865\n",
      "63m 47s (- 7m 37s) ([134/150] 89%), train loss: 1.4744 test loss: 4.9199\n",
      "64m 16s (- 7m 8s) ([135/150] 90%), train loss: 1.4729 test loss: 4.8476  **\n",
      "64m 44s (- 6m 39s) ([136/150] 90%), train loss: 1.4720 test loss: 4.8553\n",
      "65m 13s (- 6m 11s) ([137/150] 91%), train loss: 1.4697 test loss: 4.8366  **\n",
      "65m 41s (- 5m 42s) ([138/150] 92%), train loss: 1.4671 test loss: 4.8530\n",
      "66m 10s (- 5m 14s) ([139/150] 92%), train loss: 1.4653 test loss: 4.8590\n",
      "66m 38s (- 4m 45s) ([140/150] 93%), train loss: 1.4637 test loss: 4.8309  **\n",
      "67m 6s (- 4m 16s) ([141/150] 94%), train loss: 1.4625 test loss: 4.7966  **\n",
      "67m 35s (- 3m 48s) ([142/150] 94%), train loss: 1.4598 test loss: 4.8046\n",
      "68m 3s (- 3m 19s) ([143/150] 95%), train loss: 1.4590 test loss: 4.7898  **\n",
      "68m 32s (- 2m 51s) ([144/150] 96%), train loss: 1.4574 test loss: 4.7744  **\n",
      "69m 0s (- 2m 22s) ([145/150] 96%), train loss: 1.4536 test loss: 4.7773\n",
      "69m 28s (- 1m 54s) ([146/150] 97%), train loss: 1.4526 test loss: 4.7659  **\n",
      "69m 57s (- 1m 25s) ([147/150] 98%), train loss: 1.4513 test loss: 4.7499  **\n",
      "70m 25s (- 0m 57s) ([148/150] 98%), train loss: 1.4486 test loss: 4.6420  **\n",
      "70m 54s (- 0m 28s) ([149/150] 99%), train loss: 1.4475 test loss: 4.7047\n",
      "71m 22s (- -1m 59s) ([150/150] 100%), train loss: 1.4464 test loss: 4.6248  **\n"
     ]
    }
   ],
   "source": [
    "#def trainnetwork():\n",
    "num_epochs = 300\n",
    "writer=SummaryWriter() #open the tensorboard visualiser\n",
    "best_loss_on_test = np.Infinity\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    #zero out epoch based performance variables \n",
    "    all_acc = {key: 0 for key in phases} \n",
    "    all_loss = {key: torch.zeros(0).to(device) for key in phases} #keep this on GPU for greatly improved performance\n",
    "    cmatrix = {key: np.zeros((num_classes,num_classes)) for key in phases}\n",
    "\n",
    "    for phase in phases: #iterate through both training and validation states\n",
    "\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else: #when in eval mode, we don't want parameters to be updated\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        for ii , (X, label, img_orig,tab) in enumerate(dataLoader[phase]): #for each of the batches\n",
    "            X = X.to(device)  # [Nbatch, 3, H, W]\n",
    "            if np.any(np.isnan(X.cpu().numpy())) or np.any(np.isnan(tab.cpu().numpy())):\n",
    "                breakpoint()\n",
    "            label = label.type('torch.LongTensor').to(device)  # [Nbatch, 1] with class indices (0, 1, 2,...num_classes)\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'): #dynamically set gradient computation, in case of validation, this isn't needed\n",
    "                                                            #disabling is good practice and improves inference time\n",
    "\n",
    "                prediction = model(X,tab)  # [N, Nclass]\n",
    "                loss = criterion(prediction, label)\n",
    "\n",
    "\n",
    "                if phase==\"train\": #in case we're in train mode, need to do back propogation\n",
    "                    optim.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optim.step()\n",
    "                    train_loss = loss\n",
    "\n",
    "\n",
    "                all_loss[phase]=torch.cat((all_loss[phase],loss.detach().view(1,-1)))\n",
    "\n",
    "                if phase in validation_phases: #if this phase is part of validation, compute confusion matrix\n",
    "                    p=prediction.detach().cpu().numpy()\n",
    "                    cpredflat=np.argmax(p,axis=1).flatten()\n",
    "                    yflat=label.cpu().numpy().flatten()\n",
    "\n",
    "                    cmatrix[phase]=cmatrix[phase]+confusion_matrix(yflat,cpredflat, labels=range(nclasses))\n",
    "\n",
    "        all_acc[phase]=(cmatrix[phase]/cmatrix[phase].sum()).trace()\n",
    "        all_loss[phase] = all_loss[phase].cpu().numpy().mean()\n",
    "\n",
    "        #save metrics to tensorboard\n",
    "        writer.add_scalar(f'{phase}/loss', all_loss[phase], epoch)\n",
    "        if phase in validation_phases:\n",
    "            writer.add_scalar(f'{phase}/acc', all_acc[phase], epoch)\n",
    "            for r in range(nclasses):\n",
    "                for c in range(nclasses): #essentially write out confusion matrix\n",
    "                    writer.add_scalar(f'{phase}/{r}{c}', cmatrix[phase][r][c],epoch)\n",
    "\n",
    "    print('%s ([%d/%d] %d%%), train loss: %.4f test loss: %.4f' % (timeSince(start_time, (epoch+1) / num_epochs), \n",
    "                                                 epoch+1, num_epochs ,(epoch+1) / num_epochs * 100, all_loss[\"train\"], all_loss[\"val\"]),end=\"\")    \n",
    "\n",
    "    #if current loss is the best we've seen, save model state with all variables\n",
    "    #necessary for recreation\n",
    "    if all_loss[\"val\"] < best_loss_on_test:\n",
    "        best_loss_on_test = all_loss[\"val\"]\n",
    "        print(\"  **\")\n",
    "        state = {'epoch': epoch + 1,\n",
    "         'model_dict': model.state_dict(),\n",
    "         'optim_dict': optim.state_dict(),\n",
    "         'best_loss_on_test': all_loss,\n",
    "         'in_channels': in_channels,\n",
    "         'growth_rate':growth_rate,\n",
    "         'block_config':block_config,\n",
    "         'num_init_features':num_init_features,\n",
    "         'bn_size':bn_size,\n",
    "         'drop_rate':drop_rate,\n",
    "         'num_classes':num_classes}\n",
    "\n",
    "\n",
    "        torch.save(state, f\"{dataname}_densenet_best_model.pth\")\n",
    "    else:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.any(np.isnan(tab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
